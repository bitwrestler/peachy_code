syntax="proto3";

//Server implementation that starts the model and listens for requests 
service PeachyServer {
    //Submit a request (prompt) to the server
    rpc Submit (DiffRequest) returns (DiffResult);
    //Return the currently running nvidia-smi stats
    rpc GPUStats(DiffRequest) returns (DiffResult);
    //Request shutdown the server
    rpc Shutdown(Empty) returns (Empty);
    //Set server settings
    rpc ChangeSettings(Settings) returns (Empty);
}

enum PromptType {
    PromptType_USER = 0;
    PromptType_SYSTEM = 1;
}

//The Prompt item (prompt type and string value)
message PromptItem {
    //Prompt Type
    PromptType Type=1;
    //string prompt
    string Prompt=2;
}

//The Request message
message DiffRequest {
    //Request prompt string
    repeated PromptItem Request=1;
}

//The Response message
message DiffResult {
    //String array result
    repeated string Result=1;
}

//Settings message for changing the server settings from the client
message Settings {
    //float value to set the temperature of the server
    float Temperature=1;
}

message Empty {}